# Thenus_australiensis_sex_marker

## 1. Quailty control of illumina reads with fastp (fastp 0.23.4)
```bash
fastp \
        -i \"$i1\" -I \"$i2\" \
        -o result/fastp/trim.${sample}_1.fq.gz \
        -O result/fastp/trim.${sample}_2.fq.gz \
        --trim_front1 8 --trim_front2 8 \
        --length_required 50 \
        --qualified_quality_phred 25 \
        --thread 16 \
        --html result/multiqc/${sample}.report.html \
        --json result/multiqc/${sample}.report.json" >> fastp.txt
```
## 2. Genome survey using kmer distribution generated by the Illumina reads with jellyfish (v 2.01) and GenomeScope (V2.0)
```bash
ATA_DIR="data/merge"
GENOMESCOPE_SCRIPT="genomescope2.0/genomescope.R"

# Create output directory and move into it
MAIN_OUTPUT_DIR="genomescope_analysis"
mkdir -p "${MAIN_OUTPUT_DIR}"
cd "${MAIN_OUTPUT_DIR}"

# Loop through k-mer sizes and samples
for i in 30 33 36 39 42 45 48 51 54; do 
  for n in F4 M4; do

    KMC_DB="merge_${n}_k${i}_kmc"
    HISTO_FILE="merge_${n}_${i}.histo"
    OUTPUT_DIR="genomescope_output_${n}_${i}"
    
    if [[ -s "$HISTO_FILE" ]]; then
      echo "$HISTO_FILE exists and is non-empty, skipping..."
      continue
    fi

    echo "Counting k-mers for $n at k=$i..."
    if [[ ! -s "$KMC_DB.1" ]]; then
       micromamba run -n bwa kmc \
      -k${i} \
      -t36 \
      -m80 \
      -ci3 \
      -cs10000 \
      -f \
      "${DATA_DIR}/merge_${n}_R1.fastq.gz" \
      "$KMC_DB.1" \
      genomescope_analysis/tmp_kmc_dir
    fi
    if [[ ! -s "$KMC_DB.2" ]]; then
       micromamba run -n bwa kmc \
      -k${i} \
      -t36 \
      -m80 \
      -ci3 \
      -cs10000 \
      -f \
      "${DATA_DIR}/merge_${n}_R2.fastq.gz" \
      "$KMC_DB.2" \
      genomescope_analysis/tmp_kmc_dir
    fi
   
    kmc_tools simple $KMC_DB.1 $KMC_DB.2 union $KMC_DB.merged

    echo "Generating histogram for $n at k=$i..."
   kmc_tools transform "./$KMC_DB.merged" histogram "$HISTO_FILE"

    echo "Running GenomeScope for $n at k=$i..."
   Rscript "$GENOMESCOPE_SCRIPT" \
      -i "$HISTO_FILE" \
      -o "$OUTPUT_DIR" \
      -k $i

  done 
done

```
## 3. Genome assembly
### 3.1 Genome assembly using abyss2
```bash
bbnorm.sh \
  in=merge_M4_R2.fastq.gz \
  out=/norm.merge_M4_R2.fastq.gz \
  target=40 mindepth=2 threads=24 -Xmx80G \
  hist=coverage.hist \
  prefilter=t passes=2

# Define input files
READS_R1="norm.merge_M4_R1.fastq.gz"
READS_R2="norm.merge_M4_R2.fastq.gz"
OUTPUT_DIR="abyss_results_65_M"
K_MER=65
# Use the number of CPUs requested

mkdir -p $OUTPUT_DIR
cd $OUTPUT_DIR

# Run abyss-pe
 abyss-pe \
  name=Male_65\
  k=$K_MER \
  in="$READS_R1 $READS_R2" \
  B=50G \
  kc=3 \
  v=-v \
  j=43 np=2
```
### 3.2 Transcriptome assembly
```bash
nextflow run nf-core/denovotranscript \
-r 1.2.1 \
--input samplesheet.csv \
--outdir $nf \
-profile singularity \
--assemblers trinity \
--ss fr \
--busco_mode transcriptome \
--busco_lineage arthropoda_odb10 \
-c run.config \
```

```bash
cd-hit-est -i nf/results/evigene/okayset/all_assembled.okay.mrna -o transcripts.cdhit97.fa \
  -c 0.97 -aS 0.95 -G 0 -g 1 -T 64 -M 0

salmon index -t transcripts.cdhit97.fa -i salmon/idx
salmon quant -i salmon/idx -l A \
-1 nf/results/cat/pooled_reads_1.merged.fastq.gz -2 nf/results/cat/pooled_reads_2.merged.fastq.gz \
-p 64 -o salmon

perl $TRINITY_HOME/util/abundance_estimates_to_matrix.pl \
  --est_method salmon \
  --name_sample_by_basedir \
  --quant_files salmon/quant_files.txt \
  --out_prefix matrix \
  --gene_trans_map none

# Keep transcripts with TPM â‰¥ 1 in at least one sample
perl $TRINITY_HOME/util/filter_low_expr_transcripts.pl \
  --matrix matrix.isoform.TMM.EXPR.matrix --transcripts busco/transcripts.cdhit97.fa --min_expr_any 1 \
  > salmon/okay.TPM1.fa

# Use a *stricter* identity (0.995) but keep 95% coverage of the shorter
cd-hit-est -i salmon/okay.TPM1.fa -o salmon/2okay.minredund.fa \
  -c 0.97 -aS 0.95 -G 0 -g 1 -T 64 -M 0
``` 

### 3.3 RNA scaffolding of Draft Genome results using short-read RNA-seq
```bash
hisat2 -p 48 -x rnaseq/assembly -1 nf/results/cat/pooled_reads_1.merged.fastq.gz \
 -2  RNA/nf/results/cat/pooled_reads_2.merged.fastq.gz -S rnaseq/rna_aln_sam 
micromamba run -n samtools_env samtools sort -@25 -m 2G -o rnaseq/sort_rna_aln.bam rnaseq/rna_aln_sam
samtools index rnaseq/sort_rna_aln.bam

# scaffold using Rascaf
rascaf -b rnaseq/sort_rna_aln.bam -f rnaseq/rn_rascaf_scaffolded.fa -o rnaseq/rascaf_scaffolded.fa 
rascaf rascaf-join -r rnaseq/rascaf_scaffolded.fa.out -o rnaseq/rascaf_scaffolded
```
### 3.4 RNA scaffoldin of Draft Genome results using contig RNA-seq
```bash
micromamba run -n l_rna blat -stepSize=11 -repMatch=2253 -minScore=20 -minIdentity=80 rnaseq/rascaf_scaffolded.fa \
 salmon/okay.TPM1.fa \
  ./transcripts2.psl

micromamba run -n l_rna bash L_RNA_scaffolder/L_RNA_scaffolder.sh \
 -d .  \
  -j rnaseq3/rn_rascaf_scaffolded.fa \
  -i L_RNA_scaffolder/transcripts2.noheader.psl \
  -o scaffolded_genome3
```
### 3.5 Polishing of Draft Genome results using short-read DNA-seq
```bash
run-ntedit polish --draft scaffolded_genome/L_RNA_scaffolder.fasta --reads   data/merge/merge_M4 -k 31 \
-t 64  -f --solid

run-ntedit polish --draft nt/rename.ntedit_k31_edited.fa --read   data/merge/merge_M4 -k 41 \
-t 64  -f

run-ntedit polish --draft nt2/ntedit_k41_edited.fa --reads   data/merge/merge_M4 -k 25 \
-t 64  -f 
seqkit seq -m 2000 input.fasta > filtered_output.fasta
```
## 4.Gene structure prediction
### 4.1 Gene structure prediction using AUGUSTUS (v3.2.3)
```bash
# 1. Build HISAT2 index
seqkit seq -m 2000 scaffolded_genome3/assembly.fa > scaffolded_genome3/assembly.2kb.masked.fa

hisat2-build \
  scaffolded_genome3/assembly.2kb.masked.fa \
  lobster_index

# 2. Align RNA-seq reads
micromamba run -n hisat2 hisat2 -p 48 -x lobster_index \
  -1  RNA/nf/results/cat/pooled_reads_1.merged.fastq.gz \
  -2  RNA/nf/results/cat/pooled_reads_2.merged.fastq.gz | \
samtools sort -@10 -m 3G -o rna_alignments.bam
samtools index rna_alignments.bam

# 3. Run BRAKER with masked genome + RNA evidence
export GENEMARK_PATH= script_new/annotate/augustus/GeneMark-ETP/bin/gmes
export BAMTOOLS_PATH=/home/huyha/micromamba/envs/augustus/bin

 braker.pl \
  --genome= script_new/scaffolded_genome3/assembly.2kb.masked.fa  \
  --bam=rna_alignments.bam \
  --cores 84 \
  --species=slipper_lobster \
  --gff3 
```
### 4.2 Gene structure prediction using PASA (v3.2.3)
```bash
singularity exec \
  -B /mnt/12T \
  pasapipeline_latest.sif \
  /usr/local/src/PASApipeline/Launch_PASA_pipeline.pl \
  -c alignAssembly.config \
  -C -R \
  -g scaffolded_genome3/assembly.2kb.masked.fa \
  -t transcriptome_annotate/okay.TPM1.fa.clean \
  -T -u transcriptome_annotate/okay.TPM1.fa \
  --TDN tdn.accs \
  --ALIGNERS gmap,blat \
  --CPU 48
```
### 4.3 Gene structure prediction using EVM (v3.2.3)
```bash
EVidenceModeler \
  --sample_id lobster4 \
  --genome assembly.2kb.masked.fa \
  --weights evm_weights.txt \
  --gene_predictions augustus.gff3 \
  --transcript_alignments sql.pasa.lite.pasa_assemblies.gff3 \
  --min_intron_length 20 \
  --segmentSize 1000000 \
  --overlapSize 10000 \
  --CPU 48

```
### 4.4 Gene structure prediction using PASA-update (v3.2.3)
```bash
export PASAHOME=/home/huyha/micromamba/envs/pasa_env/opt/pasa-2.5.3

singularity exec \
  -B /mnt/12T \
  pasapipeline_latest.sif \
  /usr/local/src/PASApipeline/Launch_PASA_pipeline.pl \
    -c alignAssembly.config \
    -A \
    -g scaffolded_genome3/assembly.2kb.masked.fa  \
    -t transcriptome_annotate/okay.TPM1.fa.clean \
    -L \
    --annots evidenModuler/lobster3.EVM.gff3 \
    --CPU 48

```

## 5. Functional annotation
## 5.1 Diamond Blast (v0.88.2) the whole NCBI NR database (Release 2021_9_29)
```bash
diamond blastp \
  --query  anno/lobster_pasa_updated.proteins.no_stop.fasta \
  --db  db/nr.dmnd \
  --out nr.tsv \
  --outfmt 6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore stitle \
  --evalue 1e-5 \
  --max-target-seqs 1 \
  --threads 32
```
## 5.1 Diamond Blast (v0.88.2) the SWISS-PROT database (Release 2022_01)
```bash
diamond blastp \
  --query  anno/gff/lobster_pasa_updated.proteins.fasta  \
  --db  db/uniprot/uniprot_sprot.dmnd \
  --out swisprot.out \
  --outfmt 6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore stitle \
  --evalue 1e-5 \
  --max-target-seqs 1 \
  --threads 32
```
## 5.1 Protein domain annotation by interproscan (v5.52-86.0) and pfam_scan.pl
```bash
interpro/interproscan-5.75-106.0/interproscan.sh \
  -i transcriptome_annotate/lobster_pasa_updated.proteins.no_stop.fasta \
  -cpu 64 \
  -goterms \
  -iprlookup \
  -pa
```
## 5.4 Protein domain annotation by interproscan (v5.52-86.0) and pfam_scan.pl
```bash
emapper.py \
  -i  anno/gff/lobster_pasa_updated.proteins.fasta \
  --output  anno/agat_final/emmpper.out \
  -m diamond \
  --cpu 32 \
  --data_dir  db/eggnog_db
```
## Genome assessment
## 6. Noncoding RNAs prediction

### 6.1 tRNA annotation using tRNAscan-SE (v1.4)
```bash
seqkit split2 -p 20 -O chunks_dir scaffolded_genome3/rn_L_RNA_scaffolder.fasta

mkdir -p tRNAscan_chunks
mkdir -p $PWD/tmp_parallel
export TMPDIR=$PWD/tmp_parallel

parallel --tmpdir $PWD/tmp_parallel -j 20 '
  base=$(basename {} .fa);
   tRNAscan-SE --tmpdir rna/tmp  --thread 3 -m tRNAscan_chunks/${base}.stat \
              -o tRNAscan_chunks/${base}.tRNA \
              -f tRNAscan_chunks/${base}.structure \
              {}' ::: chunks_dir/*.fasta

```
### 6.2 rRNA, miRNA and snRNA annotation using INFERNAL (v1.0) form Rfam (14.5)
```bash
cmsearch --cpu 24  --rfam --tblout genome.rfam.tbl \
  rna/db/Rfam.cm \
  scaffolded_genome3/rn_L_RNA_scaffolder.fasta > genome.fa.rfam
```
### 6.3 sncRNA annotation using tRNAscan-SE (v1.4)

```bash
> 18S_ref.fasta
while read r; do
efetch -db nucleotide -id $r -format fasta >> 18S_ref.fasta
done < rna/snoscan/id.18s
> 28S_ref.fasta
while read n; do
efetch -db nucleotide -id $n -format fasta >> 28S_ref.fasta
done < rna/snoscan/id.28s
> ref_rRNA.fasta
cat 18S_ref.fasta 28S_ref.fasta > ref_rRNA.fasta
python3 make_snoscan_targets.py ref_rRNA.fasta targets.meth
seqkit split2 genome_wrapped.fasta -p 20 -O genome_parts

ls genome_parts/*.fasta | xargs -n 1 -P 20 -I {} sh -c 'snoscan -s ref_rRNA.fasta -m targets.meth "{}" > "{}.out"'

# 3. Merge results
cat genome_parts/*.out > snoscan_final.out
```

### 7. Annotation of Repeat Regions
```bash
mkdir -p SSR; cd SSR

perl MISA/25082020/outpAs.misa.pl ntedit_k25_edited.fa.PolcaCorrected.fa &>/dev/null

```

## 7 Phylogenetic analysis
```bash
mkdir -p phylogenicTree/fasta phylogenicTree/tbl phylogenicTree/4phylo

### T.aus_ortho proteein
for i in `xlsx2csv treefam_out/Treefam_Ortho_Genes.xlsx | awk -F"," 'NR>1 {print $6}'`; do
	fa=`find BUSCO/run_arthropoda_odb10/busco_sequences/single_copy_busco_sequences -name "${i}.faa"`
	cat $fa >> phylogenicTree/fasta/T.aus_ortho.faa

done

### extract target
for i in `awk 'NR>1 {print $1}' crustacea_ref/Crustacea.tsv | sort | uniq`; do
blastp -query phylogenicTree/fasta/T.aus_ortho.faa -subject crustacea_ref/ncbi_dataset/ncbi_dataset/data/$i/protein.faa -outfmt 6 -max_target_seqs 1 -out phylogenicTree/tbl/$i.tsv 
cut -f2 phylogenicTree/tbl/$i.tsv | sort | uniq > phylogenicTree/tbl/$i.list
samtools faidx crustacea_ref/ncbi_dataset/ncbi_dataset/data/$i/protein.faa -r phylogenicTree/tbl/$i.list > phylogenicTree/fasta/$i.faa
done

### count target
for i in `awk 'NR>1 {print $1}' crustacea_ref/Crustacea.tsv | sort | uniq`; do
	n=`grep ">" phylogenicTree/fasta/$i.faa | wc -l`
	echo -e "$i\t$n" >> phylogenicTree/countTarget.tsv
done

Rscript -e '
library(ggplot2)

dt=read.table("phylogenicTree/countTarget.tsv", header=F, sep="\t")

ggplot(dt, aes(x=V2)) +
geom_histogram(color="#e9ecef", alpha=0.6, position = 'identity', bins = 50) +
scale_fill_manual(values=c("#69b3a2")) +
xlab("#of genes") +
ylab("#of species")
ggsave("phylogenicTree/countTarget.pdf", width=5, height=5)
'

### concanate
for i in `awk 'NR>1 {print $1}' crustacea_ref/Crustacea.tsv | sort | uniq`; do
	cat phylogenicTree/fasta/$i.faa | sed -e '1!{/^>.*/d;}' | sed ':a;N;$!ba;s/\n//2g' | sed '1!s/.\{80\}/&\n/g' > phylogenicTree/fasta/$i.concanated.faa
	b=`grep ">" phylogenicTree/fasta/$i.concanated.faa`
	sed -i -e "s/$b/>$i/g" phylogenicTree/fasta/$i.concanated.faa
done

cat phylogenicTree/fasta/T.aus_ortho.faa | sed -e '1!{/^>.*/d;}' | sed ':a;N;$!ba;s/\n//2g' | sed '1!s/.\{80\}/&\n/g' > phylogenicTree/fasta/T.aus_ortho.concanated.faa
b=`grep ">" phylogenicTree/fasta/T.aus_ortho.concanated.faa`
sed -i -e "s/$b/>T.aus/g" phylogenicTree/fasta/T.aus_ortho.concanated.faa
sed -i -e "s/*//g" phylogenicTree/fasta/T.aus_ortho.concanated.faa

### merge for phylo
rm phylogenicTree/4phylo/merged.faa
cat phylogenicTree/fasta/*.concanated.faa >> phylogenicTree/4phylo/merged.faa

```

## 8. Finding candidate sex-specific and positive control marker
https://github.com/fengtong-bio/ssp2

### 8.1 Step one: K-mer dataset preparation
```bash

# --- Configuration ---
BASE_DIR="/mnt/10T/lobster_project"
KMC_DIR="$BASE_DIR/kmer/kmer_c"
TMP_DIR="$KMC_DIR/tmp"
SCRIPT_DIR="$BASE_DIR/script_project"
FINAL_OUT_DIR="$BASE_DIR/kmer"

# Create directories
mkdir -p "$TMP_DIR"
mkdir -p "$FINAL_OUT_DIR"

# Define k-mer sizes
kmer_sizes=(21 33 55)

# --- 1. K-mer Counting ---
run_kmc() {
    input_dir=$1
    prefix=$2
    
    # Check if directory exists
    if [ ! -d "$input_dir" ]; then
        echo "Error: Directory $input_dir does not exist."
        return
    fi

    # Filter only FASTQ files (gz or uncompressed) to avoid reading junk files
    find "$input_dir" -maxdepth 1 -name "*.fq.gz" -o -name "*.fastq.gz" -o -name "*.fq" -o -name "*.fastq" | while read i; do
        o=$(basename "$i")
        # Cleanup filename
        o=${o/merge_/}
        o=${o/trim./}
        o=${o/.fq.gz/}
        o=${o/.fastq.gz/}

        for k in "${kmer_sizes[@]}"; do
            output_db="$KMC_DIR/kmc.$prefix$o.k$k"
            
            # Skip if already exists to save time (Optional)
            if [ ! -d "$output_db" ]; then
                echo "Processing $o with k=$k..."
                kmc -k"$k" -t32 -m80 -ci2 "$i" "$output_db" "$TMP_DIR"
            else
                echo "Skipping $o (k=$k), output already exists."
            fi
        done
    done
}

# Run KMC
run_kmc "$BASE_DIR/data/merge" ""
run_kmc "$BASE_DIR/DarT-seq_data/trim" "dart."


# --- 2. Merging K-mers ---

# You might need to generate these operation files dynamically if filenames vary.
# Assuming your manually created files are correct:
kmc_tools complex "$SCRIPT_DIR/33.kmer_operate.F"
kmc_tools complex "$SCRIPT_DIR/33.kmer_operate.M"
kmc_tools complex "$SCRIPT_DIR/55.kmer_operate.F"
kmc_tools complex "$SCRIPT_DIR/55.kmer_operate.M"


# --- 3. Extract Unique K-mers (Subtraction) ---
echo "Extracting unique k-mers..."

# Function to subtract, dump, and convert to FASTA
process_unique() {
    local k=$1
    local set1=$2 # Target (e.g., F)
    local set2=$3 # Subtract (e.g., M)
    
    local in_db1="$KMC_DIR/${set1}.merged_kmc.k$k"
    local in_db2="$KMC_DIR/${set2}.merged_kmc.k$k"
    local uniq_db="$KMC_DIR/uniq_${set1}_kmc.k$k"
    local dump_txt="$KMC_DIR/3.uniq_${set1}_kmc.k$k.txt"
    local out_fasta="$FINAL_OUT_DIR/k$k.${set1}.merged_kmers.fasta"

    # Subtract
    kmc_tools simple "$in_db1" "$in_db2" kmers_subtract "$uniq_db" -ci3
    
    # Transform to text
    kmc_tools transform "$uniq_db" dump "$dump_txt" -ci3
```

### 6.2 Step two: Sex-specific k-mers and reads extraction.
```bash
#WGS
mkdir -p kmer/clean_read
mkdir -p kmer/clean_read/QC

for i in `ls kmer/clean_read/k33.clean_clean_merge_F*_R1.fastq.gz`;do
a=`echo $i | sed -e  's/R1/R2/'`
b=`basename ${a}`
c=`basename ${i}`
bbduk.sh in1=$i in2=$a ref=kmer/k55.M.merged_kmers.fasta -Xmx90g  usejni=t \
         outm1=kmer/clean_read/k55_$c outm2=kmer/clean_read/k55_$b k=21 hdist=0 \
         stats=$b.stats.txt minlength=50 &>  k55.M.$c.bbduck.log
done

for i in `ls kmer/clean_read/k33.clean_clean_merge_M*_R1.fastq.gz`;do
a=`echo $i | sed -e  's/R1/R2/'`
b=`basename ${a}`
c=`basename ${i}`
bbduk.sh in1=$i in2=$a ref=kmer/k55.F.merged_kmers.fasta -Xmx90g  usejni=t\
         outm1=kmer/clean_read/k55_$c outm2=kmer/clean_read/k55_$b k=21 hdist=0 \
         stats=$b.stats.txt minlength=50 &>  k55.F.$c.bbduck.log
done

# DarT-seq
mkdir kmer/DarT_seq_clean_read
rm -f bbduk.F.txt 
for i in kmer/DarT_seq_clean_read/k33.clean_trim.Female*.fq.gz; do
    c=$(basename "$i")  
    echo $i
    [[ -s "kmer/DarT_seq_clean_read/k55_$c" ]] || \
    bbduk.sh in="$i" ref=kmer/k55.F.merged_kmers.fasta -Xmx75g usejni=f \
             outm=kmer/DarT_seq_clean_read/k55_"$c" \
             k=21 hdist=0 stats="$c.k55.stats.txt" minlength=50 threads=8 &> k55.M."$c".bbduk.log >> bbduk.F.txt
done


rm -f bbduk.M.txt 
for i in  kmer/DarT_seq_clean_read/k33.clean_trim.Male*.fq.gz; do
    c=`basename ${i}`   
    echo $i
    [[ -s "kmer/DarT_seq_clean_read/k55_$c" ]] || \
    bbduk.sh in=$i ref=kmer/k55.M.merged_kmers.fasta -Xmx75g usejni=f \
             outm=kmer/DarT_seq_clean_read/k55_"$c" \
             k=21 hdist=0 stats=$c.k55.stats.txt minlength=50 threads=8  &> k55.M.$c.bbduck.log >> bbduk.M.txt
done


parallel -j 2 "pigz -dc -p 16 kmer/clean_read/k55_k33.clean_clean_merge_F*_{}.fastq.gz| pigz -p 8 > kmer/merged_read_filtered/Merged_F.{}.fastq.gz
" ::: R1 R2 
parallel -j 2 "pigz -dc -p 16 kmer/clean_read/k55_k33.clean_clean_merge_M*_{}.fastq.gz| pigz -p 8 > kmer/merged_read_filtered/Merged_M.{}.fastq.gz
" ::: R1 R2 

```

### 7.3 Step three: De novo assembly of sex-specific reads.
```bash
mkdir -p  kmer/megahit_output/

# assembly FeMale
megahit \
    -1  kmer/merged_read_filtered/Merged_F.R1.fastq.gz \
    -2  kmer/merged_read_filtered/Merged_F.R2.fastq.gz \
    --k-min 27 --k-max 141 --k-step 20 \
    --min-contig-len 300 \
    --num-cpu-threads 40 \
    --memory 0.95 --mem-flag 0 \
    --continue \
    -o  kmer/megahit_output/F 2>  kmer/megahit_output/F.error 

exit

# assembly Male
megahit \
    -1  kmer/merged_read_filtered/Merged_M.R1.fastq.gz \
    -2  kmer/merged_read_filtered/Merged_M.R2.fastq.gz \
    --k-min 27 --k-max 141 --k-step 20 \
    --min-contig-len 300 \
    --num-cpu-threads 40\ \
    --memory 0.95 \
    --continue \
    -o  kmer/megahit_output/M 2>  kmer/megahit_output/M.error
```

### 7.4 Step four: Check against the candidates.
```bash

# Rename and index reference genome
mv kmer/megahit_output/F/final.contigs.fa kmer/megahit_output/F/FEMALE_ref.fasta
bwa index kmer/megahit_output/F/FEMALE_ref.fasta

# Step1 maping wgs
parallel -j 3 '
    i={}
    a=$(echo "$i" | sed "s/_R1.fastq.gz/_R2.fastq.gz/")
    b=$(basename "$i" | sed "s/k55_k33.clean_clean_merge_//" | sed "s/_R1.fastq.gz//")
    bwa mem -t 40 -M -T 50 -B 5 -O 10 -E 3 -Y "kmer/megahit_output/F/FEMALE_ref.fasta" "$i" "$a" | \
    samtools view -bS ->  "kmer/bwa_result/WGS/$b.F.bam"
' :::  kmer/clean_read/k55_k33.clean_clean_merge_F3_R1.fastq.gz kmer/clean_read/k55_k33.clean_clean_merge_M1_R1.fastq.gz kmer/clean_read/k55_k33.clean_clean_merge_M2_R1.fastq.gz




# Step2 sort wgs
parallel -j 3 '
    i={}
    b=$(basename "$i" | sed "s/k55_k33.clean_clean_merge_//" | sed "s/_R1.fastq.gz//")
    samtools sort -@ 27 "kmer/bwa_result/WGS/$b.F.bam" -o "kmer/bwa_result/WGS/sort.${b}.F.bam"
' ::: kmer/clean_read/k55_k33.clean_clean_merge_F3_R1.fastq.gz kmer/clean_read/k55_k33.clean_clean_merge_M1_R1.fastq.gz kmer/clean_read/k55_k33.clean_clean_merge_M2_R1.fastq.gz

#Step3 index.sort wgs
parallel -j 6 '
    i={}
    a=$(echo "$i" | sed "s/_R1.fastq.gz/_R2.fastq.gz/")
    b=$(basename "$i" | sed "s/k55_k33.clean_clean_merge_//" | sed "s/_R1.fastq.gz//")

    samtools index "kmer/bwa_result/WGS/sort.${b}.F.bam"
' ::: kmer/clean_read/k55_k33.clean_clean_merge_F3_R1.fastq.gz kmer/clean_read/k55_k33.clean_clean_merge_M1_R1.fastq.gz kmer/clean_read/k55_k33.clean_clean_merge_M2_R1.fastq.gz
```
```bash

#Step4 maping DArT-seq 
parallel -j 4 '
    b=$(basename {} | sed "s/k33.clean_trim.//" | sed "s/.fq.gz//")
    bwa mem -t 20 -M -T 50 -B 5 -O 10 -E 3 -Y "kmer/megahit_output/F/FEMALE_ref.fasta" {} | \
    samtools view -bS -> "kmer/bwa_result/dart-seq/${b}.F.bam"
    
' ::: kmer/DarT_seq_clean_read/k33.*.fq.gz
echo Step5
#Step5 sort DArT-seq 
parallel -j 4 '
    b=$(basename {} | sed "s/k33.clean_trim.//" | sed "s/.fq.gz//")
    samtools sort -@ 20 "kmer/bwa_result/dart-seq/${b}.F.bam" -o "kmer/bwa_result/dart-seq/sort.${b}.F.bam"
    
' ::: kmer/DarT_seq_clean_read/k33.*.fq.gz

#Step6 index.sort DArT-seq 
parallel -j 8 '
    b=$(basename {} | sed "s/k33.clean_trim.//" | sed "s/.fq.gz//")
    samtools index "kmer/bwa_result/dart-seq/sort.${b}.F.bam"
' ::: kmer/DarT_seq_clean_read/k33.*.fq.gz
```
```bash
echo Step7
samtools depth -m 100000 -aa \
kmer/bwa_result/WGS/sort.F1.F.bam \
kmer/bwa_result/WGS/sort.F2.F.bam \
kmer/bwa_result/WGS/sort.F3.F.bam \
kmer/bwa_result/dart-seq/sort.Female_01_1.F.bam \
kmer/bwa_result/dart-seq/sort.Female_01_2.F.bam \
kmer/bwa_result/dart-seq/sort.Female_02_1.F.bam \
kmer/bwa_result/dart-seq/sort.Female_02_2.F.bam \
kmer/bwa_result/dart-seq/sort.Female_03_1.F.bam \
kmer/bwa_result/dart-seq/sort.Female_03_2.F.bam \
kmer/bwa_result/dart-seq/sort.Female_04_1.F.bam \
kmer/bwa_result/dart-seq/sort.Female_04_2.F.bam \
kmer/bwa_result/dart-seq/sort.Female_05_1.F.bam \
kmer/bwa_result/dart-seq/sort.Female_05_2.F.bam \
kmer/bwa_result/dart-seq/sort.Female_06_1.F.bam \
kmer/bwa_result/dart-seq/sort.Female_06_2.F.bam \
kmer/bwa_result/dart-seq/sort.Female_07_1.F.bam \
kmer/bwa_result/dart-seq/sort.Female_07_2.F.bam \
kmer/bwa_result/dart-seq/sort.Female_08_1.F.bam \
kmer/bwa_result/dart-seq/sort.Female_08_2.F.bam \
kmer/bwa_result/dart-seq/sort.Female_09_1.F.bam \
kmer/bwa_result/dart-seq/sort.Female_09_2.F.bam \
kmer/bwa_result/dart-seq/sort.Female_10.F.bam \
kmer/bwa_result/dart-seq/sort.Female_11.F.bam \
kmer/bwa_result/dart-seq/sort.Female_12.F.bam \
kmer/bwa_result/dart-seq/sort.Female_15.F.bam \
kmer/bwa_result/WGS/sort.M1.F.bam \
kmer/bwa_result/WGS/sort.M2.F.bam \
kmer/bwa_result/WGS/sort.M3.F.bam \
kmer/bwa_result/dart-seq/sort.Male_01.F.bam \
kmer/bwa_result/dart-seq/sort.Male_02.F.bam \
kmer/bwa_result/dart-seq/sort.Male_03.F.bam \
kmer/bwa_result/dart-seq/sort.Male_04.F.bam \
kmer/bwa_result/dart-seq/sort.Male_05.F.bam \
kmer/bwa_result/dart-seq/sort.Male_06.F.bam \
kmer/bwa_result/dart-seq/sort.Male_07.F.bam \
kmer/bwa_result/dart-seq/sort.Male_08.F.bam \
kmer/bwa_result/dart-seq/sort.Male_09.F.bam \
kmer/bwa_result/dart-seq/sort.Male_10.F.bam \
kmer/bwa_result/dart-seq/sort.Male_11.F.bam \
kmer/bwa_result/dart-seq/sort.Male_12.F.bam \
kmer/bwa_result/dart-seq/sort.Male_14.F.bam \
kmer/bwa_result/dart-seq/sort.Male_15_1.F.bam \
kmer/bwa_result/dart-seq/sort.Male_15_2.F.bam \
> kmer/bwa_result/FEMALE.depth

#Finding sex-marker sequences
perl canu_kmer/bwa/ssp2/step2.pl kmer/megahit_output/F/FEMALE_ref.fasta kmer/megahit_output/F/MALE_ref.fasta 25 18 kmer/bwa_result/FEMALE.depth kmer/bwa_result/MALE.depth 0.9 20 100

```

```bash
#Finding positive control sequences
awk \
-v G1_NUM=25 \
-v G2_NUM=18 \
-v GAP_LENGTH=10 \
-v MIN_LENGTH=10 \
-f  PS_region/script.awk \
 kmer/bwa_result/FEMALE.depth 

# References